\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}

\geometry{margin=1in}

\title{Lecture Summary: Linear Independence â€“ Part 2}
\author{}
\date{}

\begin{document}

\maketitle

\section*{Source: Lec31.pdf}

\section*{Key Points}

\begin{itemize}
  \item \textbf{Review of Linear Independence:}
    \begin{itemize}
      \item A set of vectors $v_1, v_2, \dots, v_n$ is \textbf{linearly independent} if the only solution to:
        \[
          a_1 v_1 + a_2 v_2 + \cdots + a_n v_n = 0
        \]
        is $a_1 = a_2 = \cdots = a_n = 0$.
      \item A set is \textbf{linearly dependent} if there exist coefficients, not all zero, that satisfy the above equation.
    \end{itemize}

  \item \textbf{Homogeneous System Approach:}
    \begin{itemize}
      \item Linear independence can be tested by checking if the homogeneous system $Vx = 0$ has only the trivial solution.
      \item Here, $V$ is the matrix formed by using the vectors $v_1, v_2, \dots, v_n$ as columns.
    \end{itemize}

  \item \textbf{Key Results:}
    \begin{itemize}
      \item If the number of vectors exceeds the dimension of the space ($n > m$), the vectors are always linearly dependent.
      \item If the number of vectors equals the dimension of the space ($n = m$), linear independence depends on whether $\det(V) \neq 0$.
    \end{itemize}

  \item \textbf{Relation to Determinants:}
    \begin{itemize}
      \item If $V$ is an $n \times n$ matrix:
        \begin{enumerate}
          \item If $\det(V) = 0$, the vectors are linearly dependent.
          \item If $\det(V) \neq 0$, the vectors are linearly independent.
        \end{enumerate}
    \end{itemize}
\end{itemize}

\section*{Simplified Explanation}

\textbf{Example 1: Checking Independence in $\mathbb{R}^2$}
Given vectors $(5, 2)$ and $(1, 3)$:
\[
  x_1(5, 2) + x_2(1, 3) = (0, 0).
\]
This results in the equations:
\[
  5x_1 + x_2 = 0, \quad 2x_1 + 3x_2 = 0.
\]
The determinant of the corresponding matrix is:
\[
  \det
  \begin{bmatrix}
    5 & 1 \\
    2 & 3
  \end{bmatrix} = 13 \neq 0.
\]
Hence, $(5, 2)$ and $(1, 3)$ are linearly independent.

\textbf{Example 2: Dependency in $\mathbb{R}^2$ with Three Vectors}
Given $(1, 2)$, $(1, 3)$, and $(3, 4)$:
\[
  x_1(1, 2) + x_2(1, 3) + x_3(3, 4) = (0, 0).
\]
The augmented matrix is:
\[
  \begin{bmatrix}
    1 & 1 & 3 \\
    2 & 3 & 4
  \end{bmatrix}.
\]
Gaussian elimination reveals infinitely many solutions, indicating the vectors are linearly dependent.

\textbf{Example 3: Independence in $\mathbb{R}^3$}
Given $(1, 2, 0)$, $(0, 2, 4)$, and $(3, 0, 0)$:
\[
  x_1(1, 2, 0) + x_2(0, 2, 4) + x_3(3, 0, 0) = (0, 0, 0).
\]
The determinant of the matrix:
\[
  \begin{bmatrix}
    1 & 0 & 3 \\
    2 & 2 & 0 \\
    0 & 4 & 0
  \end{bmatrix} = 24 \neq 0.
\]
Thus, the vectors are linearly independent.

\textbf{Example 4: Dependency with Four Vectors in $\mathbb{R}^3$}
Given $(1, 2, 0)$, $(0, 2, 4)$, $(3, 0, 0)$, and $(1, 2, 3)$:
\[
  x_1(1, 2, 0) + x_2(0, 2, 4) + x_3(3, 0, 0) + x_4(1, 2, 3) = (0, 0, 0).
\]
Gaussian elimination yields a free variable, confirming the vectors are linearly dependent.

\section*{Conclusion}

In this lecture, we:
\begin{itemize}
  \item Discussed the homogeneous system approach to determining linear independence.
  \item Explored examples using both determinant checks and Gaussian elimination.
  \item Highlighted that more vectors than the space's dimension ($n > m$) always result in dependence.
\end{itemize}

This framework unifies linear independence testing, bridging algebraic and geometric interpretations.

\end{document}
